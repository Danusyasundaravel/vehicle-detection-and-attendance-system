{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danusyasundaravel/vehicle-detection-and-attendance-system/blob/main/task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGrAIa9OOTIz",
        "outputId": "53033cd9-ffe1-464c-f375-57623a51fe67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Vehicle\"\n",
        "\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        try:\n",
        "            img = Image.open(file_path)\n",
        "            img.verify()  # Verify that it is an image\n",
        "        except (IOError, SyntaxError) as e:\n",
        "            print(f\"Corrupted file: {file_path}\")\n",
        "            os.remove(file_path)  # Remove corrupted file\n"
      ],
      "metadata": {
        "id": "e0VOE2-AWx4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
      ],
      "metadata": {
        "id": "mhZA4gtVW25R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import os\n",
        "# Step 1: Define paths and parameters\n",
        "train_data_dir = \"/content/drive/MyDrive/Vehicle\"  # Replace with the path to your dataset\n",
        "image_size = (224, 224)  # Image size suitable for MobileNetV2\n",
        "batch_size = 32\n",
        "classes = [\"Mahindra Scorpio\", \"Truck\", \"non-vechicles\",\"scanned vehicle image\"]\n",
        "\n",
        "# Step 2: Data augmentation and loading\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # 20% validation split\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgYgSfYAaQb8",
        "outputId": "5498a62c-6ed5-4166-8ca0-c51d850e72cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1588 images belonging to 4 classes.\n",
            "Found 395 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load the pretrained model (MobileNetV2)\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(image_size[0], image_size[1], 3),\n",
        "    include_top=False,  # Remove the fully connected layer\n",
        "    weights=\"imagenet\"  # Use weights pre-trained on ImageNet\n",
        ")\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Step 4: Build the Transfer Learning Model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(classes), activation=\"softmax\")  # Output layer for your classes\n",
        "])\n",
        "\n",
        "# Step 5: Compile the Model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Step 6: Train the Model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX1WvRRKaVut",
        "outputId": "4c0ab23f-f656-43eb-b066-bd702b035832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 169s 3s/step - loss: 0.3925 - accuracy: 0.8501 - val_loss: 0.1395 - val_accuracy: 0.9494\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 157s 3s/step - loss: 0.1686 - accuracy: 0.9339 - val_loss: 0.1013 - val_accuracy: 0.9620\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 160s 3s/step - loss: 0.1112 - accuracy: 0.9591 - val_loss: 0.0960 - val_accuracy: 0.9570\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 158s 3s/step - loss: 0.0884 - accuracy: 0.9691 - val_loss: 0.0757 - val_accuracy: 0.9646\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 157s 3s/step - loss: 0.0765 - accuracy: 0.9736 - val_loss: 0.1216 - val_accuracy: 0.9468\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 159s 3s/step - loss: 0.0664 - accuracy: 0.9754 - val_loss: 0.0656 - val_accuracy: 0.9696\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 156s 3s/step - loss: 0.0954 - accuracy: 0.9666 - val_loss: 0.0664 - val_accuracy: 0.9747\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 157s 3s/step - loss: 0.0556 - accuracy: 0.9824 - val_loss: 0.0583 - val_accuracy: 0.9772\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 159s 3s/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.0747 - val_accuracy: 0.9722\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 157s 3s/step - loss: 0.0492 - accuracy: 0.9843 - val_loss: 0.0695 - val_accuracy: 0.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"vehicle_detection_model.h5\")\n",
        "model.save(\"vehicle_detection.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bWs5j0xeyPc",
        "outputId": "58b52734-c821-4653-efd1-59a4394eb3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"/content/vehicle_detection_model.h5\")"
      ],
      "metadata": {
        "id": "tsmIIzzQ4EZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Fine-tune the Model (optional)\n",
        "# Unfreeze the base model and train with a lower learning rate\n",
        "base_model.trainable = True\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "fine_tune_epochs = 5\n",
        "history_fine_tune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=fine_tune_epochs,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m7jzsmOaZRQ",
        "outputId": "1d68080e-1e3a-4f24-9500-8c57db84c84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "50/50 [==============================] - 418s 8s/step - loss: 0.2707 - accuracy: 0.9074 - val_loss: 0.1403 - val_accuracy: 0.9494\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 396s 8s/step - loss: 0.0539 - accuracy: 0.9849 - val_loss: 0.0618 - val_accuracy: 0.9823\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 389s 8s/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 0.0887 - val_accuracy: 0.9772\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 388s 8s/step - loss: 0.0357 - accuracy: 0.9893 - val_loss: 0.1037 - val_accuracy: 0.9671\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 386s 8s/step - loss: 0.0224 - accuracy: 0.9912 - val_loss: 0.0625 - val_accuracy: 0.9772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"detection_model1.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpDJ8OVRiML4",
        "outputId": "110c6ef5-8af0-45d7-8938-06a139fcf04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Function to classify a new image\n",
        "def classify_image(image_path):\n",
        "    img = load_img(image_path, target_size=image_size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = classes[np.argmax(predictions)]\n",
        "    confidence = np.max(predictions) * 100\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Test the model\n",
        "image_path = \"/content/Datacluster Truck (92).jpg\"  # Replace with a test image path\n",
        "predicted_class, confidence = classify_image(image_path)\n",
        "print(f\"Predicted class: {predicted_class} with confidence: {confidence:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3JNs_l_hcAy",
        "outputId": "1879ab4f-c713-4cdd-9d3f-64dc4928fee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 766ms/step\n",
            "Predicted class: Truck with confidence: 99.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Function to classify a new image\n",
        "def classify_image(image_path):\n",
        "    img = load_img(image_path, target_size=image_size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = classes[np.argmax(predictions)]\n",
        "    confidence = np.max(predictions) * 100\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Test the model\n",
        "image_path = \"/content/68.jpg\"  # Replace with a test image path\n",
        "predicted_class, confidence = classify_image(image_path)\n",
        "print(f\"Predicted class: {predicted_class} with confidence: {confidence:.2f}%\")\n"
      ],
      "metadata": {
        "id": "fiuC_KZiSkWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd25876-aec1-4dfb-b171-ddf26b3ba27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n",
            "Predicted class: Mahindra Scorpio with confidence: 99.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Function to classify a new image\n",
        "def classify_image(image_path):\n",
        "    img = load_img(image_path, target_size=image_size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = classes[np.argmax(predictions)]\n",
        "    confidence = np.max(predictions) * 100\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Test the model\n",
        "image_path = \"/content/IMG_20241203_222215.jpg\"  # Replace with a test image path\n",
        "predicted_class, confidence = classify_image(image_path)\n",
        "print(f\"Predicted class: {predicted_class} with confidence: {confidence:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIGRqUTilNRw",
        "outputId": "77493eb6-724e-401e-c32b-3f55ee4b526f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n",
            "Predicted class: scanned vehicle image with confidence: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Function to classify a new image\n",
        "def classify_image(image_path):\n",
        "    img = load_img(image_path, target_size=image_size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = classes[np.argmax(predictions)]\n",
        "    confidence = np.max(predictions) * 100\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Test the model\n",
        "image_path = \"/content/image1838.png\"  # Replace with a test image path\n",
        "predicted_class, confidence = classify_image(image_path)\n",
        "print(f\"Predicted class: {predicted_class} with confidence: {confidence:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H10qZvV5l0mh",
        "outputId": "e5d9a183-a9f3-49ad-8673-6441905d1eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "Predicted class: non-vechicles with confidence: 100.00%\n"
          ]
        }
      ]
    }
  ]
}